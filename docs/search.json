[{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Lihua Lei. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Lei L (2023). transferUQ: Uncertainty quantification transferability prediction models. R package version 0.1.0.","code":"@Manual{,   title = {transferUQ: Uncertainty quantification for transferability of prediction models},   author = {Lihua Lei},   year = {2023},   note = {R package version 0.1.0}, }"},{"path":"/index.html","id":"transferuq","dir":"","previous_headings":"","what":"Uncertainty quantification for transferability of prediction models","title":"Uncertainty quantification for transferability of prediction models","text":"R package uncertainty quantification transfer performance prediction models","code":""},{"path":"/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Uncertainty quantification for transferability of prediction models","text":"R package implements forecast intervals confidence intervals transfer errors prediction models using observations multiple domains, along comparison two prediction models terms worst-case- everywhere-dominance. methods introduced paper: Transfer Performance Economics Models. also includes dataset CertaintyEquivalents analyzed paper, includes unnormalized normalized transfer error matrices certainty equivalents binary lotteries 44 domains. full description functions can found manual [package site] ()","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Uncertainty quantification for transferability of prediction models","text":"package requires lpSolve installed. access vignette, run following code build . Make sure knitr, rmarkdown, latex2exp, tidyverse installed.","code":"if (!require(\"devtools\")){     install.packages(\"devtools\") } devtools::install_github(\"lihualei71/transferUQ\") devtools::install_github(\"lihualei71/transferUQ\", build_vignettes = TRUE)"},{"path":"/index.html","id":"usage-examples","dir":"","previous_headings":"","what":"Usage Examples","title":"Uncertainty quantification for transferability of prediction models","text":"illustrate usage transferUQ package using CertaintyEquivalents dataset. details please read vignette (vignette(\"transferUQ_demo\", package = \"transferUQ\")) manual.","code":"library(\"transferUQ\")  # Extract the unnormalized transfor error matrix for the CPT model and Random Forests err_CPT <- CertaintyEquivalents$unnormalized[[\"abdg\"]] err_RF <- CertaintyEquivalents$unnormalized[[\"RF\"]]  # Compute 80% two-sided forecast intervals forecast_interval(err_CPT, 0.8) forecast_interval(err_RF, 0.8)  # Compute 80% two-sided confidence intervals for the median transfer errors qte_interval(err_CPT, 0.8, betas = 0.5) qte_interval(err_RF, 0.8, betas = 0.5)  # Check if CPT worst-case-upper-dominates RF check_worstcase_dominance(err_CPT, err_RF)  # Check if CPT everywhere-upper-dominates RF check_everywhere_dominance(err_CPT, err_RF)"},{"path":"/reference/CertaintyEquivalents.html","id":null,"dir":"Reference","previous_headings":"","what":"Transfer error matrices on certainty equivalents for binary lotteries — CertaintyEquivalents","title":"Transfer error matrices on certainty equivalents for binary lotteries — CertaintyEquivalents","text":"CertaintyEquivalents$unnormalized CertaintyEquivalents$normalized record unnormalized normalized transfer errors certainty equivalents dataset 17 models across 44 domains.","code":""},{"path":"/reference/CertaintyEquivalents.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transfer error matrices on certainty equivalents for binary lotteries — CertaintyEquivalents","text":"","code":"CertaintyEquivalents"},{"path":"/reference/CertaintyEquivalents.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Transfer error matrices on certainty equivalents for binary lotteries — CertaintyEquivalents","text":"object class list length 2.","code":""},{"path":"/reference/ETE_interval.html","id":null,"dir":"Reference","previous_headings":"","what":"Confidence interval for expected transfer errors — ete_interval","title":"Confidence interval for expected transfer errors — ete_interval","text":"ete_interval generates one- two-sided forecast intervals expected transfer errors (Section 5.3) given coverage level. function requires transfer error bounded [0, bd].","code":""},{"path":"/reference/ETE_interval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confidence interval for expected transfer errors — ete_interval","text":"","code":"ete_interval(err, coverage, side = c(\"two\", \"left\", \"right\"), bd = 1, r = NULL)"},{"path":"/reference/ETE_interval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Confidence interval for expected transfer errors — ete_interval","text":"err error object; see Details coverage target coverage level side \"two\" two-sided, \"left\" intervals form \\([, \\infty)\\), \"right\" intervals form \\((-\\infty, ]\\) bd upper bound loss function; 1 default r number training domains (optional); see Details","code":""},{"path":"/reference/ETE_interval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Confidence interval for expected transfer errors — ete_interval","text":"2-d vector giving left right ends confidence interval","code":""},{"path":"/reference/ETE_interval.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Confidence interval for expected transfer errors — ete_interval","text":"err one following forms. square asymmetric matrix number training domains \\(r = 1\\). case, err[, j] records transfer error using -th domain training j-th domain testing. data.frame \\((r+2)\\) columns. last column records transfer errors, second last column records indices test domains, first r columns record indices training domains. (recommended) data.frame two columns. second column records transfer errors first column records indices test domains. version, recommended include transfer errors n-choose-(r+1) combinations training test domains. Otherwise, ete_interval can still output interval, though theoretical guarantee unclear. input r specified err data.frame two columns (.e., without training domain indices).","code":""},{"path":"/reference/ETE_interval.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Confidence interval for expected transfer errors — ete_interval","text":"","code":"# Generate an error matrix n <- 100 set.seed(1) errmat <- matrix(runif(n^2), nrow = n) diag(errmat) <- NA  # Two-sided confidence interval ete_interval(errmat, 0.9, \"two\", 1) #> [1] 0.3921159 0.6175157  # One-sided confidence intervals ete_interval(errmat, 0.9, \"left\", 1) #> [1] 0.4065942       Inf ete_interval(errmat, 0.9, \"right\", 1) #> [1]      -Inf 0.6031261  # Generate an error data.frame with r+2=3 columns idx <- expand.grid(train = 1:n, test = 1:n) errdf <- cbind(idx, data.frame(val = as.numeric(errmat))) errdf <- errdf[!is.na(errdf$val), ] ete_interval(errdf, 0.9, \"two\", 1) #> [1] 0.3921159 0.6175157 ete_interval(errmat, 0.9, \"two\", 1) #> [1] 0.3921159 0.6175157  # Generate an error data.frame with only two columns (not recommended) errdf2 <- errdf[, 2:3] ete_interval(errdf2, 0.9, \"two\", 1, r = 1) #> [1] 0.3921159 0.6175157  # Generate an error data.frame with r>1 n <- 40 set.seed(1) idx <- expand.grid(train1 = 1:n, train2 = 1:n, test = 1:n) idx <- idx[idx$train1 != idx$train2 & idx$train1 != idx$test & idx$train2 != idx$test, ] err <- cbind(idx, data.frame(val = runif(nrow(idx))))  # Two-sided confidence interval ete_interval(err, 0.9, \"two\", 1) #> [1] 0.2601725 0.7547201  # One-sided confidence intervals ete_interval(err, 0.9, \"left\", 1) #> [1] 0.2880356       Inf ete_interval(err, 0.9, \"right\", 1) #> [1]      -Inf 0.7270833"},{"path":"/reference/Gamma_curve.html","id":null,"dir":"Reference","previous_headings":"","what":"The worst-case transfer error \\(\\bar{e}_{\\tau}(\\Gamma)\\) as\na function of \\(\\tau\\) for a given \\(\\Gamma\\). — Gamma_curve","title":"The worst-case transfer error \\(\\bar{e}_{\\tau}(\\Gamma)\\) as\na function of \\(\\tau\\) for a given \\(\\Gamma\\). — Gamma_curve","text":"worst-case transfer error \\(\\bar{e}_{\\tau}(\\Gamma)\\) function \\(\\tau\\) given \\(\\Gamma\\).","code":""},{"path":"/reference/Gamma_curve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The worst-case transfer error \\(\\bar{e}_{\\tau}(\\Gamma)\\) as\na function of \\(\\tau\\) for a given \\(\\Gamma\\). — Gamma_curve","text":"","code":"Gamma_curve(errmat, Gamma)"},{"path":"/reference/Gamma_curve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The worst-case transfer error \\(\\bar{e}_{\\tau}(\\Gamma)\\) as\na function of \\(\\tau\\) for a given \\(\\Gamma\\). — Gamma_curve","text":"errmat square matrix errmat[, j] transfer error using -th domain training j-th domain testing Gamma Gamma value selection bias","code":""},{"path":"/reference/Gamma_curve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The worst-case transfer error \\(\\bar{e}_{\\tau}(\\Gamma)\\) as\na function of \\(\\tau\\) for a given \\(\\Gamma\\). — Gamma_curve","text":"data.frame two columns: prob turning points \\(\\tau\\) \\(\\bar{e}_{\\tau}(\\Gamma)\\) changes val corresponding bounds","code":""},{"path":"/reference/HBM_mean_upper.html","id":null,"dir":"Reference","previous_headings":"","what":"Upper/Lower confidence bound of mean of U-statistics of order k\nvia Hoeffding-Bentkus-Maurer inequalities — HBM_mean_upper","title":"Upper/Lower confidence bound of mean of U-statistics of order k\nvia Hoeffding-Bentkus-Maurer inequalities — HBM_mean_upper","text":"Upper/Lower confidence bound mean U-statistics order k via Hoeffding-Bentkus-Maurer inequalities","code":""},{"path":"/reference/HBM_mean_upper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Upper/Lower confidence bound of mean of U-statistics of order k\nvia Hoeffding-Bentkus-Maurer inequalities — HBM_mean_upper","text":"","code":"HBM_mean_upper(U, n, k, alpha)"},{"path":"/reference/HBM_mean_upper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Upper/Lower confidence bound of mean of U-statistics of order k\nvia Hoeffding-Bentkus-Maurer inequalities — HBM_mean_upper","text":"U value U-statistic n sample size k order U-statistic alpha confidence level","code":""},{"path":"/reference/HBM_quantile_lower.html","id":null,"dir":"Reference","previous_headings":"","what":"Upper/Lower confidence bound for uhat defined in the note\nvia Hoeffding-Bentkus-Maurer inequalities — HBM_quantile_lower","title":"Upper/Lower confidence bound for uhat defined in the note\nvia Hoeffding-Bentkus-Maurer inequalities — HBM_quantile_lower","text":"Upper/Lower confidence bound uhat defined note via Hoeffding-Bentkus-Maurer inequalities","code":""},{"path":"/reference/HBM_quantile_lower.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Upper/Lower confidence bound for uhat defined in the note\nvia Hoeffding-Bentkus-Maurer inequalities — HBM_quantile_lower","text":"","code":"HBM_quantile_lower(beta, n, k, alpha)"},{"path":"/reference/HBM_quantile_lower.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Upper/Lower confidence bound for uhat defined in the note\nvia Hoeffding-Bentkus-Maurer inequalities — HBM_quantile_lower","text":"beta quantile n sample size k order U-statistic alpha confidence level","code":""},{"path":"/reference/QTE_interval.html","id":null,"dir":"Reference","previous_headings":"","what":"Confidence interval for quantile transfer errors — qte_interval","title":"Confidence interval for quantile transfer errors — qte_interval","text":"qte_interval generates one- two-sided forecast intervals quantile transfer errors (Section 5.2) given coverage level.","code":""},{"path":"/reference/QTE_interval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confidence interval for quantile transfer errors — qte_interval","text":"","code":"qte_interval(   err,   coverage,   side = c(\"two\", \"left\", \"right\"),   betas = seq(0.2, 0.8, 0.01),   r = NULL )"},{"path":"/reference/QTE_interval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Confidence interval for quantile transfer errors — qte_interval","text":"err error object; see Details coverage target coverage level side \"two\" two-sided, \"left\" intervals form \\([, \\infty)\\), \"right\" intervals form \\((-\\infty, ]\\) betas vector quantiles confidence intervals computed; seq(0.2, 0.8, 0.01) default r number training domains (optional); see Details","code":""},{"path":"/reference/QTE_interval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Confidence interval for quantile transfer errors — qte_interval","text":"data.frame three columns: beta quantile, lb lower confidence bound, ub upper confidence bound","code":""},{"path":"/reference/QTE_interval.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Confidence interval for quantile transfer errors — qte_interval","text":"err one following forms. square asymmetric matrix number training domains \\(r = 1\\). case, err[, j] records transfer error using -th domain training j-th domain testing. data.frame \\((r+2)\\) columns. last column records transfer errors, second last column records indices test domains, first r columns record indices training domains. (recommended) data.frame two columns. second column records transfer errors first column records indices test domains. version, recommended include transfer errors n-choose-(r+1) combinations training test domains. Otherwise, ete_interval can still output interval, though theoretical guarantee unclear. input r specified err data.frame two columns (.e., without training domain indices).","code":""},{"path":"/reference/QTE_interval.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Confidence interval for quantile transfer errors — qte_interval","text":"","code":"# Generate an error matrix n <- 100 set.seed(1) errmat <- matrix(runif(n^2), nrow = n) diag(errmat) <- NA  # Two-sided confidence intervals for  qte_interval(errmat, 0.9, \"two\") #>    beta        lb        ub #> 1  0.20 0.1066140 0.2972971 #> 2  0.21 0.1175638 0.3084541 #> 3  0.22 0.1275388 0.3213396 #> 4  0.23 0.1363064 0.3304364 #> 5  0.24 0.1383513 0.3386547 #> 6  0.25 0.1486186 0.3482244 #> 7  0.26 0.1587195 0.3571679 #> 8  0.27 0.1676721 0.3677980 #> 9  0.28 0.1767802 0.3868504 #> 10 0.29 0.1867239 0.3975490 #> 11 0.30 0.1985937 0.4059733 #> 12 0.31 0.2093228 0.4152536 #> 13 0.32 0.2093793 0.4253134 #> 14 0.33 0.2203054 0.4359764 #> 15 0.34 0.2316049 0.4450060 #> 16 0.35 0.2424557 0.4549541 #> 17 0.36 0.2523173 0.4660721 #> 18 0.37 0.2600172 0.4763512 #> 19 0.38 0.2694677 0.4859278 #> 20 0.39 0.2785364 0.4963501 #> 21 0.40 0.2864735 0.5061868 #> 22 0.41 0.2972971 0.5158239 #> 23 0.42 0.3084541 0.5270490 #> 24 0.43 0.3213396 0.5367687 #> 25 0.44 0.3303951 0.5470796 #> 26 0.45 0.3386257 0.5566381 #> 27 0.46 0.3481136 0.5657588 #> 28 0.47 0.3570989 0.5765720 #> 29 0.48 0.3676554 0.5870442 #> 30 0.49 0.3782400 0.5964485 #> 31 0.50 0.3868504 0.6085399 #> 32 0.51 0.3975490 0.6205871 #> 33 0.52 0.4057905 0.6306702 #> 34 0.53 0.4152536 0.6418838 #> 35 0.54 0.4253134 0.6524722 #> 36 0.55 0.4359764 0.6626783 #> 37 0.56 0.4449026 0.6746300 #> 38 0.57 0.4548571 0.6851848 #> 39 0.58 0.4657103 0.6938516 #> 40 0.59 0.4762174 0.7044788 #> 41 0.60 0.4858570 0.7152832 #> 42 0.61 0.4962979 0.7244906 #> 43 0.62 0.5061738 0.7365522 #> 44 0.63 0.5157929 0.7477577 #> 45 0.64 0.5266529 0.7572496 #> 46 0.65 0.5366694 0.7671372 #> 47 0.66 0.5470378 0.7772063 #> 48 0.67 0.5566381 0.7860536 #> 49 0.68 0.5657588 0.7956458 #> 50 0.69 0.5765720 0.7957468 #> 51 0.70 0.5870351 0.8072118 #> 52 0.71 0.5964485 0.8195300 #> 53 0.72 0.6085399 0.8282519 #> 54 0.73 0.6305977 0.8381724 #> 55 0.74 0.6417573 0.8475366 #> 56 0.75 0.6524612 0.8579006 #> 57 0.76 0.6622595 0.8656097 #> 58 0.77 0.6745298 0.8668086 #> 59 0.78 0.6851848 0.8754056 #> 60 0.79 0.6938516 0.8835077 #> 61 0.80 0.7044788 0.8948194  # One-sided confidence intervals qte_interval(errmat, 0.9, \"left\") #>    beta        lb  ub #> 1  0.20 0.1175638 Inf #> 2  0.21 0.1276254 Inf #> 3  0.22 0.1363064 Inf #> 4  0.23 0.1485884 Inf #> 5  0.24 0.1586782 Inf #> 6  0.25 0.1603988 Inf #> 7  0.26 0.1676721 Inf #> 8  0.27 0.1769432 Inf #> 9  0.28 0.1870651 Inf #> 10 0.29 0.1988728 Inf #> 11 0.30 0.2093793 Inf #> 12 0.31 0.2202845 Inf #> 13 0.32 0.2312934 Inf #> 14 0.33 0.2422464 Inf #> 15 0.34 0.2522641 Inf #> 16 0.35 0.2600091 Inf #> 17 0.36 0.2694595 Inf #> 18 0.37 0.2694677 Inf #> 19 0.38 0.2785764 Inf #> 20 0.39 0.2866094 Inf #> 21 0.40 0.2973202 Inf #> 22 0.41 0.3088552 Inf #> 23 0.42 0.3213551 Inf #> 24 0.43 0.3304364 Inf #> 25 0.44 0.3386547 Inf #> 26 0.45 0.3482244 Inf #> 27 0.46 0.3571679 Inf #> 28 0.47 0.3677980 Inf #> 29 0.48 0.3782795 Inf #> 30 0.49 0.3868808 Inf #> 31 0.50 0.3977061 Inf #> 32 0.51 0.4059831 Inf #> 33 0.52 0.4153180 Inf #> 34 0.53 0.4254052 Inf #> 35 0.54 0.4361067 Inf #> 36 0.55 0.4450060 Inf #> 37 0.56 0.4549541 Inf #> 38 0.57 0.4660721 Inf #> 39 0.58 0.4763512 Inf #> 40 0.59 0.4859278 Inf #> 41 0.60 0.4963501 Inf #> 42 0.61 0.5061868 Inf #> 43 0.62 0.5158239 Inf #> 44 0.63 0.5270490 Inf #> 45 0.64 0.5367687 Inf #> 46 0.65 0.5470796 Inf #> 47 0.66 0.5566381 Inf #> 48 0.67 0.5657588 Inf #> 49 0.68 0.5866970 Inf #> 50 0.69 0.5963389 Inf #> 51 0.70 0.6085112 Inf #> 52 0.71 0.6204966 Inf #> 53 0.72 0.6305977 Inf #> 54 0.73 0.6417573 Inf #> 55 0.74 0.6524722 Inf #> 56 0.75 0.6626783 Inf #> 57 0.76 0.6746300 Inf #> 58 0.77 0.6851848 Inf #> 59 0.78 0.6938516 Inf #> 60 0.79 0.7151967 Inf #> 61 0.80 0.7243485 Inf qte_interval(errmat, 0.9, \"right\") #>    beta   lb        ub #> 1  0.20 -Inf 0.2785764 #> 2  0.21 -Inf 0.2866094 #> 3  0.22 -Inf 0.3084541 #> 4  0.23 -Inf 0.3213396 #> 5  0.24 -Inf 0.3303951 #> 6  0.25 -Inf 0.3386257 #> 7  0.26 -Inf 0.3481136 #> 8  0.27 -Inf 0.3571679 #> 9  0.28 -Inf 0.3677980 #> 10 0.29 -Inf 0.3782795 #> 11 0.30 -Inf 0.3868808 #> 12 0.31 -Inf 0.3977061 #> 13 0.32 -Inf 0.4059831 #> 14 0.33 -Inf 0.4253134 #> 15 0.34 -Inf 0.4359764 #> 16 0.35 -Inf 0.4449026 #> 17 0.36 -Inf 0.4548571 #> 18 0.37 -Inf 0.4657103 #> 19 0.38 -Inf 0.4762174 #> 20 0.39 -Inf 0.4858570 #> 21 0.40 -Inf 0.4962979 #> 22 0.41 -Inf 0.5061738 #> 23 0.42 -Inf 0.5157929 #> 24 0.43 -Inf 0.5266529 #> 25 0.44 -Inf 0.5366694 #> 26 0.45 -Inf 0.5470378 #> 27 0.46 -Inf 0.5566173 #> 28 0.47 -Inf 0.5657163 #> 29 0.48 -Inf 0.5765529 #> 30 0.49 -Inf 0.5866970 #> 31 0.50 -Inf 0.5963389 #> 32 0.51 -Inf 0.6085112 #> 33 0.52 -Inf 0.6204966 #> 34 0.53 -Inf 0.6305977 #> 35 0.54 -Inf 0.6417573 #> 36 0.55 -Inf 0.6524612 #> 37 0.56 -Inf 0.6622595 #> 38 0.57 -Inf 0.6745298 #> 39 0.58 -Inf 0.6851075 #> 40 0.59 -Inf 0.6938311 #> 41 0.60 -Inf 0.7041099 #> 42 0.61 -Inf 0.7151967 #> 43 0.62 -Inf 0.7243485 #> 44 0.63 -Inf 0.7365522 #> 45 0.64 -Inf 0.7367111 #> 46 0.65 -Inf 0.7479934 #> 47 0.66 -Inf 0.7573015 #> 48 0.67 -Inf 0.7671705 #> 49 0.68 -Inf 0.7772292 #> 50 0.69 -Inf 0.7860697 #> 51 0.70 -Inf 0.7956458 #> 52 0.71 -Inf 0.8071607 #> 53 0.72 -Inf 0.8191545 #> 54 0.73 -Inf 0.8280750 #> 55 0.74 -Inf 0.8381724 #> 56 0.75 -Inf 0.8465710 #> 57 0.76 -Inf 0.8476254 #> 58 0.77 -Inf 0.8579599 #> 59 0.78 -Inf 0.8668086 #> 60 0.79 -Inf 0.8753213 #> 61 0.80 -Inf 0.8835077  # Generate an error data.frame with r+2=3 columns idx <- expand.grid(train = 1:n, test = 1:n) errdf <- cbind(idx, data.frame(val = as.numeric(errmat))) errdf <- errdf[!is.na(errdf$val), ] qte_interval(errdf, 0.9, \"two\") #>    beta        lb        ub #> 1  0.20 0.1066140 0.2972971 #> 2  0.21 0.1175638 0.3084541 #> 3  0.22 0.1275388 0.3213396 #> 4  0.23 0.1363064 0.3304364 #> 5  0.24 0.1383513 0.3386547 #> 6  0.25 0.1486186 0.3482244 #> 7  0.26 0.1587195 0.3571679 #> 8  0.27 0.1676721 0.3677980 #> 9  0.28 0.1767802 0.3868504 #> 10 0.29 0.1867239 0.3975490 #> 11 0.30 0.1985937 0.4059733 #> 12 0.31 0.2093228 0.4152536 #> 13 0.32 0.2093793 0.4253134 #> 14 0.33 0.2203054 0.4359764 #> 15 0.34 0.2316049 0.4450060 #> 16 0.35 0.2424557 0.4549541 #> 17 0.36 0.2523173 0.4660721 #> 18 0.37 0.2600172 0.4763512 #> 19 0.38 0.2694677 0.4859278 #> 20 0.39 0.2785364 0.4963501 #> 21 0.40 0.2864735 0.5061868 #> 22 0.41 0.2972971 0.5158239 #> 23 0.42 0.3084541 0.5270490 #> 24 0.43 0.3213396 0.5367687 #> 25 0.44 0.3303951 0.5470796 #> 26 0.45 0.3386257 0.5566381 #> 27 0.46 0.3481136 0.5657588 #> 28 0.47 0.3570989 0.5765720 #> 29 0.48 0.3676554 0.5870442 #> 30 0.49 0.3782400 0.5964485 #> 31 0.50 0.3868504 0.6085399 #> 32 0.51 0.3975490 0.6205871 #> 33 0.52 0.4057905 0.6306702 #> 34 0.53 0.4152536 0.6418838 #> 35 0.54 0.4253134 0.6524722 #> 36 0.55 0.4359764 0.6626783 #> 37 0.56 0.4449026 0.6746300 #> 38 0.57 0.4548571 0.6851848 #> 39 0.58 0.4657103 0.6938516 #> 40 0.59 0.4762174 0.7044788 #> 41 0.60 0.4858570 0.7152832 #> 42 0.61 0.4962979 0.7244906 #> 43 0.62 0.5061738 0.7365522 #> 44 0.63 0.5157929 0.7477577 #> 45 0.64 0.5266529 0.7572496 #> 46 0.65 0.5366694 0.7671372 #> 47 0.66 0.5470378 0.7772063 #> 48 0.67 0.5566381 0.7860536 #> 49 0.68 0.5657588 0.7956458 #> 50 0.69 0.5765720 0.7957468 #> 51 0.70 0.5870351 0.8072118 #> 52 0.71 0.5964485 0.8195300 #> 53 0.72 0.6085399 0.8282519 #> 54 0.73 0.6305977 0.8381724 #> 55 0.74 0.6417573 0.8475366 #> 56 0.75 0.6524612 0.8579006 #> 57 0.76 0.6622595 0.8656097 #> 58 0.77 0.6745298 0.8668086 #> 59 0.78 0.6851848 0.8754056 #> 60 0.79 0.6938516 0.8835077 #> 61 0.80 0.7044788 0.8948194 qte_interval(errmat, 0.9, \"two\") #>    beta        lb        ub #> 1  0.20 0.1066140 0.2972971 #> 2  0.21 0.1175638 0.3084541 #> 3  0.22 0.1275388 0.3213396 #> 4  0.23 0.1363064 0.3304364 #> 5  0.24 0.1383513 0.3386547 #> 6  0.25 0.1486186 0.3482244 #> 7  0.26 0.1587195 0.3571679 #> 8  0.27 0.1676721 0.3677980 #> 9  0.28 0.1767802 0.3868504 #> 10 0.29 0.1867239 0.3975490 #> 11 0.30 0.1985937 0.4059733 #> 12 0.31 0.2093228 0.4152536 #> 13 0.32 0.2093793 0.4253134 #> 14 0.33 0.2203054 0.4359764 #> 15 0.34 0.2316049 0.4450060 #> 16 0.35 0.2424557 0.4549541 #> 17 0.36 0.2523173 0.4660721 #> 18 0.37 0.2600172 0.4763512 #> 19 0.38 0.2694677 0.4859278 #> 20 0.39 0.2785364 0.4963501 #> 21 0.40 0.2864735 0.5061868 #> 22 0.41 0.2972971 0.5158239 #> 23 0.42 0.3084541 0.5270490 #> 24 0.43 0.3213396 0.5367687 #> 25 0.44 0.3303951 0.5470796 #> 26 0.45 0.3386257 0.5566381 #> 27 0.46 0.3481136 0.5657588 #> 28 0.47 0.3570989 0.5765720 #> 29 0.48 0.3676554 0.5870442 #> 30 0.49 0.3782400 0.5964485 #> 31 0.50 0.3868504 0.6085399 #> 32 0.51 0.3975490 0.6205871 #> 33 0.52 0.4057905 0.6306702 #> 34 0.53 0.4152536 0.6418838 #> 35 0.54 0.4253134 0.6524722 #> 36 0.55 0.4359764 0.6626783 #> 37 0.56 0.4449026 0.6746300 #> 38 0.57 0.4548571 0.6851848 #> 39 0.58 0.4657103 0.6938516 #> 40 0.59 0.4762174 0.7044788 #> 41 0.60 0.4858570 0.7152832 #> 42 0.61 0.4962979 0.7244906 #> 43 0.62 0.5061738 0.7365522 #> 44 0.63 0.5157929 0.7477577 #> 45 0.64 0.5266529 0.7572496 #> 46 0.65 0.5366694 0.7671372 #> 47 0.66 0.5470378 0.7772063 #> 48 0.67 0.5566381 0.7860536 #> 49 0.68 0.5657588 0.7956458 #> 50 0.69 0.5765720 0.7957468 #> 51 0.70 0.5870351 0.8072118 #> 52 0.71 0.5964485 0.8195300 #> 53 0.72 0.6085399 0.8282519 #> 54 0.73 0.6305977 0.8381724 #> 55 0.74 0.6417573 0.8475366 #> 56 0.75 0.6524612 0.8579006 #> 57 0.76 0.6622595 0.8656097 #> 58 0.77 0.6745298 0.8668086 #> 59 0.78 0.6851848 0.8754056 #> 60 0.79 0.6938516 0.8835077 #> 61 0.80 0.7044788 0.8948194  # Generate an error data.frame with only two columns (not recommended) errdf2 <- errdf[, 2:3] qte_interval(errdf2, 0.9, \"two\", r = 1) #>    beta        lb        ub #> 1  0.20 0.1066140 0.2972971 #> 2  0.21 0.1175638 0.3084541 #> 3  0.22 0.1275388 0.3213396 #> 4  0.23 0.1363064 0.3304364 #> 5  0.24 0.1383513 0.3386547 #> 6  0.25 0.1486186 0.3482244 #> 7  0.26 0.1587195 0.3571679 #> 8  0.27 0.1676721 0.3677980 #> 9  0.28 0.1767802 0.3868504 #> 10 0.29 0.1867239 0.3975490 #> 11 0.30 0.1985937 0.4059733 #> 12 0.31 0.2093228 0.4152536 #> 13 0.32 0.2093793 0.4253134 #> 14 0.33 0.2203054 0.4359764 #> 15 0.34 0.2316049 0.4450060 #> 16 0.35 0.2424557 0.4549541 #> 17 0.36 0.2523173 0.4660721 #> 18 0.37 0.2600172 0.4763512 #> 19 0.38 0.2694677 0.4859278 #> 20 0.39 0.2785364 0.4963501 #> 21 0.40 0.2864735 0.5061868 #> 22 0.41 0.2972971 0.5158239 #> 23 0.42 0.3084541 0.5270490 #> 24 0.43 0.3213396 0.5367687 #> 25 0.44 0.3303951 0.5470796 #> 26 0.45 0.3386257 0.5566381 #> 27 0.46 0.3481136 0.5657588 #> 28 0.47 0.3570989 0.5765720 #> 29 0.48 0.3676554 0.5870442 #> 30 0.49 0.3782400 0.5964485 #> 31 0.50 0.3868504 0.6085399 #> 32 0.51 0.3975490 0.6205871 #> 33 0.52 0.4057905 0.6306702 #> 34 0.53 0.4152536 0.6418838 #> 35 0.54 0.4253134 0.6524722 #> 36 0.55 0.4359764 0.6626783 #> 37 0.56 0.4449026 0.6746300 #> 38 0.57 0.4548571 0.6851848 #> 39 0.58 0.4657103 0.6938516 #> 40 0.59 0.4762174 0.7044788 #> 41 0.60 0.4858570 0.7152832 #> 42 0.61 0.4962979 0.7244906 #> 43 0.62 0.5061738 0.7365522 #> 44 0.63 0.5157929 0.7477577 #> 45 0.64 0.5266529 0.7572496 #> 46 0.65 0.5366694 0.7671372 #> 47 0.66 0.5470378 0.7772063 #> 48 0.67 0.5566381 0.7860536 #> 49 0.68 0.5657588 0.7956458 #> 50 0.69 0.5765720 0.7957468 #> 51 0.70 0.5870351 0.8072118 #> 52 0.71 0.5964485 0.8195300 #> 53 0.72 0.6085399 0.8282519 #> 54 0.73 0.6305977 0.8381724 #> 55 0.74 0.6417573 0.8475366 #> 56 0.75 0.6524612 0.8579006 #> 57 0.76 0.6622595 0.8656097 #> 58 0.77 0.6745298 0.8668086 #> 59 0.78 0.6851848 0.8754056 #> 60 0.79 0.6938516 0.8835077 #> 61 0.80 0.7044788 0.8948194  # Generate an error data.frame with r>1 n <- 40 set.seed(1) idx <- expand.grid(train1 = 1:n, train2 = 1:n, test = 1:n) idx <- idx[idx$train1 != idx$train2 & idx$train1 != idx$test & idx$train2 != idx$test, ] err <- cbind(idx, data.frame(val = runif(nrow(idx))))  # Two-sided confidence interval qte_interval(err, 0.9, \"two\") #>    beta         lb        ub #> 1  0.20 0.02087908 0.4429732 #> 2  0.21 0.02571981 0.4512823 #> 3  0.22 0.03048572 0.4698191 #> 4  0.23 0.03533921 0.4815596 #> 5  0.24 0.04060512 0.4939273 #> 6  0.25 0.04643773 0.5008505 #> 7  0.26 0.05269740 0.5009484 #> 8  0.27 0.05893249 0.5306480 #> 9  0.28 0.06520408 0.5426520 #> 10 0.29 0.07101725 0.5510013 #> 11 0.30 0.07734347 0.5510506 #> 12 0.31 0.08344604 0.5767140 #> 13 0.32 0.09015863 0.5879448 #> 14 0.33 0.09702212 0.5986472 #> 15 0.34 0.10370848 0.6007049 #> 16 0.35 0.11107091 0.6201845 #> 17 0.36 0.11772061 0.6304324 #> 18 0.37 0.12473407 0.6414682 #> 19 0.38 0.13257015 0.6505695 #> 20 0.39 0.14000806 0.6507092 #> 21 0.40 0.14876270 0.6736191 #> 22 0.41 0.15585009 0.6829266 #> 23 0.42 0.16379647 0.6929666 #> 24 0.43 0.17237300 0.7011994 #> 25 0.44 0.18094622 0.7013571 #> 26 0.45 0.18931630 0.7218434 #> 27 0.46 0.19947046 0.7314863 #> 28 0.47 0.20657667 0.7408075 #> 29 0.48 0.21516615 0.7501577 #> 30 0.49 0.22379806 0.7516569 #> 31 0.50 0.23298005 0.7680290 #> 32 0.51 0.24913997 0.7764529 #> 33 0.52 0.25099996 0.7847993 #> 34 0.53 0.26012807 0.7933010 #> 35 0.54 0.26897830 0.8005132 #> 36 0.55 0.27872004 0.8108488 #> 37 0.56 0.29906252 0.8195448 #> 38 0.57 0.29921233 0.8275147 #> 39 0.58 0.30800500 0.8357669 #> 40 0.59 0.31880688 0.8438169 #> 41 0.60 0.32895818 0.8510989 #> 42 0.61 0.34949979 0.8598986 #> 43 0.62 0.34960480 0.8670830 #> 44 0.63 0.35912946 0.8741497 #> 45 0.64 0.36987340 0.8816154 #> 46 0.65 0.38067725 0.8889118 #> 47 0.66 0.40011966 0.8966193 #> 48 0.67 0.40296619 0.9029618 #> 49 0.68 0.41411805 0.9101871 #> 50 0.69 0.42531778 0.9164333 #> 51 0.70 0.45129906 0.9231510 #> 52 0.71 0.45145036 0.9301239 #> 53 0.72 0.46039197 0.9356604 #> 54 0.73 0.47217847 0.9420181 #> 55 0.74 0.50087986 0.9481845 #> 56 0.75 0.50096532 0.9543238 #> 57 0.76 0.50722878 0.9600113 #> 58 0.77 0.52010865 0.9657438 #> 59 0.78 0.53333044 0.9706339 #> 60 0.79 0.55109455 0.9756008 #> 61 0.80 0.55899153 0.9800203  # One-sided confidence intervals qte_interval(err, 0.9, \"left\") #>    beta         lb  ub #> 1  0.20 0.03684136 Inf #> 2  0.21 0.04233510 Inf #> 3  0.22 0.04882992 Inf #> 4  0.23 0.05505696 Inf #> 5  0.24 0.06114342 Inf #> 6  0.25 0.06749113 Inf #> 7  0.26 0.07362378 Inf #> 8  0.27 0.07992458 Inf #> 9  0.28 0.08667786 Inf #> 10 0.29 0.09283363 Inf #> 11 0.30 0.10015000 Inf #> 12 0.31 0.10712930 Inf #> 13 0.32 0.11414776 Inf #> 14 0.33 0.12110156 Inf #> 15 0.34 0.12860822 Inf #> 16 0.35 0.13625896 Inf #> 17 0.36 0.14858843 Inf #> 18 0.37 0.15200182 Inf #> 19 0.38 0.16002972 Inf #> 20 0.39 0.16809375 Inf #> 21 0.40 0.17675498 Inf #> 22 0.41 0.18532806 Inf #> 23 0.42 0.19930781 Inf #> 24 0.43 0.20208515 Inf #> 25 0.44 0.21062332 Inf #> 26 0.45 0.21930235 Inf #> 27 0.46 0.22823266 Inf #> 28 0.47 0.23742042 Inf #> 29 0.48 0.24929062 Inf #> 30 0.49 0.25504015 Inf #> 31 0.50 0.26404638 Inf #> 32 0.51 0.27276605 Inf #> 33 0.52 0.28264049 Inf #> 34 0.53 0.29906666 Inf #> 35 0.54 0.30171481 Inf #> 36 0.55 0.31185147 Inf #> 37 0.56 0.32207582 Inf #> 38 0.57 0.33175925 Inf #> 39 0.58 0.34953518 Inf #> 40 0.59 0.35119913 Inf #> 41 0.60 0.36181225 Inf #> 42 0.61 0.37187009 Inf #> 43 0.62 0.38240689 Inf #> 44 0.63 0.40027519 Inf #> 45 0.64 0.40400250 Inf #> 46 0.65 0.41500921 Inf #> 47 0.66 0.42573330 Inf #> 48 0.67 0.45132927 Inf #> 49 0.68 0.45141129 Inf #> 50 0.69 0.45935207 Inf #> 51 0.70 0.47092973 Inf #> 52 0.71 0.48155690 Inf #> 53 0.72 0.50096016 Inf #> 54 0.73 0.50450503 Inf #> 55 0.74 0.51666674 Inf #> 56 0.75 0.52849824 Inf #> 57 0.76 0.55098485 Inf #> 58 0.77 0.55304017 Inf #> 59 0.78 0.56552499 Inf #> 60 0.79 0.57785437 Inf #> 61 0.80 0.60064772 Inf qte_interval(err, 0.9, \"right\") #>    beta   lb        ub #> 1  0.20 -Inf 0.4001979 #> 2  0.21 -Inf 0.4237560 #> 3  0.22 -Inf 0.4366534 #> 4  0.23 -Inf 0.4491128 #> 5  0.24 -Inf 0.4514688 #> 6  0.25 -Inf 0.4739121 #> 7  0.26 -Inf 0.4853755 #> 8  0.27 -Inf 0.4971377 #> 9  0.28 -Inf 0.5008729 #> 10 0.29 -Inf 0.5201453 #> 11 0.30 -Inf 0.5322180 #> 12 0.31 -Inf 0.5435117 #> 13 0.32 -Inf 0.5510068 #> 14 0.33 -Inf 0.5510480 #> 15 0.34 -Inf 0.5763069 #> 16 0.35 -Inf 0.5871102 #> 17 0.36 -Inf 0.5975254 #> 18 0.37 -Inf 0.6005412 #> 19 0.38 -Inf 0.6183004 #> 20 0.39 -Inf 0.6285069 #> 21 0.40 -Inf 0.6388683 #> 22 0.41 -Inf 0.6491878 #> 23 0.42 -Inf 0.6506163 #> 24 0.43 -Inf 0.6702055 #> 25 0.44 -Inf 0.6799042 #> 26 0.45 -Inf 0.6899618 #> 27 0.46 -Inf 0.6992904 #> 28 0.47 -Inf 0.7013505 #> 29 0.48 -Inf 0.7178748 #> 30 0.49 -Inf 0.7274959 #> 31 0.50 -Inf 0.7369096 #> 32 0.51 -Inf 0.7456916 #> 33 0.52 -Inf 0.7515881 #> 34 0.53 -Inf 0.7634421 #> 35 0.54 -Inf 0.7723346 #> 36 0.55 -Inf 0.7802523 #> 37 0.56 -Inf 0.7889030 #> 38 0.57 -Inf 0.7977615 #> 39 0.58 -Inf 0.8007279 #> 40 0.59 -Inf 0.8151849 #> 41 0.60 -Inf 0.8231084 #> 42 0.61 -Inf 0.8312829 #> 43 0.62 -Inf 0.8399166 #> 44 0.63 -Inf 0.8477964 #> 45 0.64 -Inf 0.8514129 #> 46 0.65 -Inf 0.8633200 #> 47 0.66 -Inf 0.8706842 #> 48 0.67 -Inf 0.8776399 #> 49 0.68 -Inf 0.8852263 #> 50 0.69 -Inf 0.8928340 #> 51 0.70 -Inf 0.9001180 #> 52 0.71 -Inf 0.9068163 #> 53 0.72 -Inf 0.9134085 #> 54 0.73 -Inf 0.9202161 #> 55 0.74 -Inf 0.9270695 #> 56 0.75 -Inf 0.9335034 #> 57 0.76 -Inf 0.9398609 #> 58 0.77 -Inf 0.9459763 #> 59 0.78 -Inf 0.9522348 #> 60 0.79 -Inf 0.9579973 #> 61 0.80 -Inf 0.9641382"},{"path":"/reference/check_everywhere_dominance.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if method 1 everywhere-upper-dominates method 2 — check_everywhere_dominance","title":"Check if method 1 everywhere-upper-dominates method 2 — check_everywhere_dominance","text":"check_everywhere_dominance evaluates whether method 1 everywhere-upper-dominates method 2 tau-th quantile (Appendix Q.2).","code":""},{"path":"/reference/check_everywhere_dominance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if method 1 everywhere-upper-dominates method 2 — check_everywhere_dominance","text":"","code":"check_everywhere_dominance(err1, err2, taulist = seq(0.5, 1, 0.01))"},{"path":"/reference/check_everywhere_dominance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if method 1 everywhere-upper-dominates method 2 — check_everywhere_dominance","text":"err1 error object method 1; see Details err2 error object method 2; see Details taulist vector quantiles methods compared","code":""},{"path":"/reference/check_everywhere_dominance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if method 1 everywhere-upper-dominates method 2 — check_everywhere_dominance","text":"data.frame two columns: first column records values \\(\\tau\\) second column records whether method 1 everywhere-upper-dominates method 2 quantile","code":""},{"path":"/reference/check_everywhere_dominance.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check if method 1 everywhere-upper-dominates method 2 — check_everywhere_dominance","text":"err one following forms. square asymmetric matrix number training domains \\(r = 1\\). case, err[, j] records transfer error using -th domain training j-th domain testing. data.frame \\((r+2)\\) columns. last column records transfer errors, second last column records indices test domains, first r columns record indices training domains. (recommended) data.frame two columns. second column records transfer errors first column records indices test domains. version, recommended include transfer errors n-choose-(r+1) combinations training test domains. Otherwise, ete_interval can still output interval, though theoretical guarantee unclear.","code":""},{"path":"/reference/check_everywhere_dominance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check if method 1 everywhere-upper-dominates method 2 — check_everywhere_dominance","text":"","code":"# Generate three error matrices such that # errmat1 and errmat2 are similar  # and errmat1 is smaller than errmat3 n <- 40 set.seed(1) errmat1 <- matrix(runif(n^2), nrow = n) errmat2 <- matrix(runif(n^2), nrow = n) errmat3 <- errmat1 + 0.1 diag(errmat1) <- diag(errmat2) <- diag(errmat3) <- NA  check_everywhere_dominance(errmat1, errmat2) #>     tau   res #> 1  0.50 FALSE #> 2  0.51 FALSE #> 3  0.52 FALSE #> 4  0.53 FALSE #> 5  0.54 FALSE #> 6  0.55 FALSE #> 7  0.56 FALSE #> 8  0.57 FALSE #> 9  0.58 FALSE #> 10 0.59 FALSE #> 11 0.60 FALSE #> 12 0.61 FALSE #> 13 0.62 FALSE #> 14 0.63 FALSE #> 15 0.64 FALSE #> 16 0.65 FALSE #> 17 0.66 FALSE #> 18 0.67 FALSE #> 19 0.68 FALSE #> 20 0.69 FALSE #> 21 0.70 FALSE #> 22 0.71 FALSE #> 23 0.72 FALSE #> 24 0.73 FALSE #> 25 0.74 FALSE #> 26 0.75 FALSE #> 27 0.76 FALSE #> 28 0.77 FALSE #> 29 0.78 FALSE #> 30 0.79 FALSE #> 31 0.80 FALSE #> 32 0.81 FALSE #> 33 0.82 FALSE #> 34 0.83 FALSE #> 35 0.84 FALSE #> 36 0.85 FALSE #> 37 0.86 FALSE #> 38 0.87 FALSE #> 39 0.88 FALSE #> 40 0.89 FALSE #> 41 0.90 FALSE #> 42 0.91 FALSE #> 43 0.92 FALSE #> 44 0.93 FALSE #> 45 0.94 FALSE #> 46 0.95 FALSE #> 47 0.96 FALSE #> 48 0.97 FALSE #> 49 0.98 FALSE #> 50 0.99 FALSE #> 51 1.00 FALSE check_everywhere_dominance(errmat1, errmat3) #>     tau  res #> 1  0.50 TRUE #> 2  0.51 TRUE #> 3  0.52 TRUE #> 4  0.53 TRUE #> 5  0.54 TRUE #> 6  0.55 TRUE #> 7  0.56 TRUE #> 8  0.57 TRUE #> 9  0.58 TRUE #> 10 0.59 TRUE #> 11 0.60 TRUE #> 12 0.61 TRUE #> 13 0.62 TRUE #> 14 0.63 TRUE #> 15 0.64 TRUE #> 16 0.65 TRUE #> 17 0.66 TRUE #> 18 0.67 TRUE #> 19 0.68 TRUE #> 20 0.69 TRUE #> 21 0.70 TRUE #> 22 0.71 TRUE #> 23 0.72 TRUE #> 24 0.73 TRUE #> 25 0.74 TRUE #> 26 0.75 TRUE #> 27 0.76 TRUE #> 28 0.77 TRUE #> 29 0.78 TRUE #> 30 0.79 TRUE #> 31 0.80 TRUE #> 32 0.81 TRUE #> 33 0.82 TRUE #> 34 0.83 TRUE #> 35 0.84 TRUE #> 36 0.85 TRUE #> 37 0.86 TRUE #> 38 0.87 TRUE #> 39 0.88 TRUE #> 40 0.89 TRUE #> 41 0.90 TRUE #> 42 0.91 TRUE #> 43 0.92 TRUE #> 44 0.93 TRUE #> 45 0.94 TRUE #> 46 0.95 TRUE #> 47 0.96 TRUE #> 48 0.97 TRUE #> 49 0.98 TRUE #> 50 0.99 TRUE #> 51 1.00 TRUE  # Transform error matrices into data.frames with r+2=3 columns idx <- expand.grid(train = 1:n, test = 1:n) errdf1 <- cbind(idx, data.frame(val = as.numeric(errmat1))) errdf1 <- errdf1[!is.na(errdf1$val), ] errdf2 <- cbind(idx, data.frame(val = as.numeric(errmat2))) errdf2 <- errdf2[!is.na(errdf2$val), ] errdf3 <- cbind(idx, data.frame(val = as.numeric(errmat3))) errdf3 <- errdf3[!is.na(errdf3$val), ]  check_everywhere_dominance(errdf1, errdf2) #>     tau   res #> 1  0.50 FALSE #> 2  0.51 FALSE #> 3  0.52 FALSE #> 4  0.53 FALSE #> 5  0.54 FALSE #> 6  0.55 FALSE #> 7  0.56 FALSE #> 8  0.57 FALSE #> 9  0.58 FALSE #> 10 0.59 FALSE #> 11 0.60 FALSE #> 12 0.61 FALSE #> 13 0.62 FALSE #> 14 0.63 FALSE #> 15 0.64 FALSE #> 16 0.65 FALSE #> 17 0.66 FALSE #> 18 0.67 FALSE #> 19 0.68 FALSE #> 20 0.69 FALSE #> 21 0.70 FALSE #> 22 0.71 FALSE #> 23 0.72 FALSE #> 24 0.73 FALSE #> 25 0.74 FALSE #> 26 0.75 FALSE #> 27 0.76 FALSE #> 28 0.77 FALSE #> 29 0.78 FALSE #> 30 0.79 FALSE #> 31 0.80 FALSE #> 32 0.81 FALSE #> 33 0.82 FALSE #> 34 0.83 FALSE #> 35 0.84 FALSE #> 36 0.85 FALSE #> 37 0.86 FALSE #> 38 0.87 FALSE #> 39 0.88 FALSE #> 40 0.89 FALSE #> 41 0.90 FALSE #> 42 0.91 FALSE #> 43 0.92 FALSE #> 44 0.93 FALSE #> 45 0.94 FALSE #> 46 0.95 FALSE #> 47 0.96 FALSE #> 48 0.97 FALSE #> 49 0.98 FALSE #> 50 0.99 FALSE #> 51 1.00 FALSE check_everywhere_dominance(errdf1, errdf3) #>     tau  res #> 1  0.50 TRUE #> 2  0.51 TRUE #> 3  0.52 TRUE #> 4  0.53 TRUE #> 5  0.54 TRUE #> 6  0.55 TRUE #> 7  0.56 TRUE #> 8  0.57 TRUE #> 9  0.58 TRUE #> 10 0.59 TRUE #> 11 0.60 TRUE #> 12 0.61 TRUE #> 13 0.62 TRUE #> 14 0.63 TRUE #> 15 0.64 TRUE #> 16 0.65 TRUE #> 17 0.66 TRUE #> 18 0.67 TRUE #> 19 0.68 TRUE #> 20 0.69 TRUE #> 21 0.70 TRUE #> 22 0.71 TRUE #> 23 0.72 TRUE #> 24 0.73 TRUE #> 25 0.74 TRUE #> 26 0.75 TRUE #> 27 0.76 TRUE #> 28 0.77 TRUE #> 29 0.78 TRUE #> 30 0.79 TRUE #> 31 0.80 TRUE #> 32 0.81 TRUE #> 33 0.82 TRUE #> 34 0.83 TRUE #> 35 0.84 TRUE #> 36 0.85 TRUE #> 37 0.86 TRUE #> 38 0.87 TRUE #> 39 0.88 TRUE #> 40 0.89 TRUE #> 41 0.90 TRUE #> 42 0.91 TRUE #> 43 0.92 TRUE #> 44 0.93 TRUE #> 45 0.94 TRUE #> 46 0.95 TRUE #> 47 0.96 TRUE #> 48 0.97 TRUE #> 49 0.98 TRUE #> 50 0.99 TRUE #> 51 1.00 TRUE  # Transform error matrices into data.frames with only two columns (not recommended) errdf1_2 <- errdf1[, 2:3] errdf2_2 <- errdf2[, 2:3] errdf3_2 <- errdf3[, 2:3]  check_everywhere_dominance(errdf1_2, errdf2_2) #>     tau   res #> 1  0.50 FALSE #> 2  0.51 FALSE #> 3  0.52 FALSE #> 4  0.53 FALSE #> 5  0.54 FALSE #> 6  0.55 FALSE #> 7  0.56 FALSE #> 8  0.57 FALSE #> 9  0.58 FALSE #> 10 0.59 FALSE #> 11 0.60 FALSE #> 12 0.61 FALSE #> 13 0.62 FALSE #> 14 0.63 FALSE #> 15 0.64 FALSE #> 16 0.65 FALSE #> 17 0.66 FALSE #> 18 0.67 FALSE #> 19 0.68 FALSE #> 20 0.69 FALSE #> 21 0.70 FALSE #> 22 0.71 FALSE #> 23 0.72 FALSE #> 24 0.73 FALSE #> 25 0.74 FALSE #> 26 0.75 FALSE #> 27 0.76 FALSE #> 28 0.77 FALSE #> 29 0.78 FALSE #> 30 0.79 FALSE #> 31 0.80 FALSE #> 32 0.81 FALSE #> 33 0.82 FALSE #> 34 0.83 FALSE #> 35 0.84 FALSE #> 36 0.85 FALSE #> 37 0.86 FALSE #> 38 0.87 FALSE #> 39 0.88 FALSE #> 40 0.89 FALSE #> 41 0.90 FALSE #> 42 0.91 FALSE #> 43 0.92 FALSE #> 44 0.93 FALSE #> 45 0.94 FALSE #> 46 0.95 FALSE #> 47 0.96 FALSE #> 48 0.97 FALSE #> 49 0.98 FALSE #> 50 0.99 FALSE #> 51 1.00 FALSE check_everywhere_dominance(errdf1_2, errdf3_2) #>     tau  res #> 1  0.50 TRUE #> 2  0.51 TRUE #> 3  0.52 TRUE #> 4  0.53 TRUE #> 5  0.54 TRUE #> 6  0.55 TRUE #> 7  0.56 TRUE #> 8  0.57 TRUE #> 9  0.58 TRUE #> 10 0.59 TRUE #> 11 0.60 TRUE #> 12 0.61 TRUE #> 13 0.62 TRUE #> 14 0.63 TRUE #> 15 0.64 TRUE #> 16 0.65 TRUE #> 17 0.66 TRUE #> 18 0.67 TRUE #> 19 0.68 TRUE #> 20 0.69 TRUE #> 21 0.70 TRUE #> 22 0.71 TRUE #> 23 0.72 TRUE #> 24 0.73 TRUE #> 25 0.74 TRUE #> 26 0.75 TRUE #> 27 0.76 TRUE #> 28 0.77 TRUE #> 29 0.78 TRUE #> 30 0.79 TRUE #> 31 0.80 TRUE #> 32 0.81 TRUE #> 33 0.82 TRUE #> 34 0.83 TRUE #> 35 0.84 TRUE #> 36 0.85 TRUE #> 37 0.86 TRUE #> 38 0.87 TRUE #> 39 0.88 TRUE #> 40 0.89 TRUE #> 41 0.90 TRUE #> 42 0.91 TRUE #> 43 0.92 TRUE #> 44 0.93 TRUE #> 45 0.94 TRUE #> 46 0.95 TRUE #> 47 0.96 TRUE #> 48 0.97 TRUE #> 49 0.98 TRUE #> 50 0.99 TRUE #> 51 1.00 TRUE  # Generate an error data.frame with r>1 n <- 20 set.seed(1) idx <- expand.grid(train1 = 1:n, train2 = 1:n, test = 1:n) idx <- idx[idx$train1 != idx$train2 & idx$train1 != idx$test & idx$train2 != idx$test, ] err1 <- cbind(idx, data.frame(val = runif(nrow(idx)))) err2 <- cbind(idx, data.frame(val = runif(nrow(idx)))) err3 <- cbind(idx, data.frame(val = err1$val + 0.1))  check_everywhere_dominance(err1, err2) #>     tau   res #> 1  0.50 FALSE #> 2  0.51 FALSE #> 3  0.52 FALSE #> 4  0.53 FALSE #> 5  0.54 FALSE #> 6  0.55 FALSE #> 7  0.56 FALSE #> 8  0.57 FALSE #> 9  0.58 FALSE #> 10 0.59 FALSE #> 11 0.60 FALSE #> 12 0.61 FALSE #> 13 0.62 FALSE #> 14 0.63 FALSE #> 15 0.64 FALSE #> 16 0.65 FALSE #> 17 0.66 FALSE #> 18 0.67 FALSE #> 19 0.68 FALSE #> 20 0.69 FALSE #> 21 0.70 FALSE #> 22 0.71 FALSE #> 23 0.72 FALSE #> 24 0.73 FALSE #> 25 0.74 FALSE #> 26 0.75 FALSE #> 27 0.76 FALSE #> 28 0.77 FALSE #> 29 0.78 FALSE #> 30 0.79 FALSE #> 31 0.80 FALSE #> 32 0.81 FALSE #> 33 0.82 FALSE #> 34 0.83 FALSE #> 35 0.84 FALSE #> 36 0.85 FALSE #> 37 0.86 FALSE #> 38 0.87 FALSE #> 39 0.88 FALSE #> 40 0.89 FALSE #> 41 0.90 FALSE #> 42 0.91 FALSE #> 43 0.92 FALSE #> 44 0.93 FALSE #> 45 0.94 FALSE #> 46 0.95 FALSE #> 47 0.96 FALSE #> 48 0.97 FALSE #> 49 0.98 FALSE #> 50 0.99 FALSE #> 51 1.00 FALSE check_everywhere_dominance(err1, err3) #>     tau  res #> 1  0.50 TRUE #> 2  0.51 TRUE #> 3  0.52 TRUE #> 4  0.53 TRUE #> 5  0.54 TRUE #> 6  0.55 TRUE #> 7  0.56 TRUE #> 8  0.57 TRUE #> 9  0.58 TRUE #> 10 0.59 TRUE #> 11 0.60 TRUE #> 12 0.61 TRUE #> 13 0.62 TRUE #> 14 0.63 TRUE #> 15 0.64 TRUE #> 16 0.65 TRUE #> 17 0.66 TRUE #> 18 0.67 TRUE #> 19 0.68 TRUE #> 20 0.69 TRUE #> 21 0.70 TRUE #> 22 0.71 TRUE #> 23 0.72 TRUE #> 24 0.73 TRUE #> 25 0.74 TRUE #> 26 0.75 TRUE #> 27 0.76 TRUE #> 28 0.77 TRUE #> 29 0.78 TRUE #> 30 0.79 TRUE #> 31 0.80 TRUE #> 32 0.81 TRUE #> 33 0.82 TRUE #> 34 0.83 TRUE #> 35 0.84 TRUE #> 36 0.85 TRUE #> 37 0.86 TRUE #> 38 0.87 TRUE #> 39 0.88 TRUE #> 40 0.89 TRUE #> 41 0.90 TRUE #> 42 0.91 TRUE #> 43 0.92 TRUE #> 44 0.93 TRUE #> 45 0.94 TRUE #> 46 0.95 TRUE #> 47 0.96 TRUE #> 48 0.97 TRUE #> 49 0.98 TRUE #> 50 0.99 TRUE #> 51 1.00 TRUE"},{"path":"/reference/check_worstcase_dominance.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if method 1 worst-case-upper-dominates method 2 — check_worstcase_dominance","title":"Check if method 1 worst-case-upper-dominates method 2 — check_worstcase_dominance","text":"check_worstcase_dominance evaluates whether method 1 worst-case-upper-dominates method 2 tau-th quantile \\(w\\[\\Gamma^{-1}, \\Gamma]\\). definition Appendix Q.1 corresponds \\(\\Gamma = \\infty\\).","code":""},{"path":"/reference/check_worstcase_dominance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if method 1 worst-case-upper-dominates method 2 — check_worstcase_dominance","text":"","code":"check_worstcase_dominance(err1, err2, taulist = seq(0.5, 1, 0.01), Gamma = Inf)"},{"path":"/reference/check_worstcase_dominance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if method 1 worst-case-upper-dominates method 2 — check_worstcase_dominance","text":"err1 error object method 1; see Details err2 error object method 2; see Details taulist vector quantiles methods compared Gamma scalar. Inf default","code":""},{"path":"/reference/check_worstcase_dominance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if method 1 worst-case-upper-dominates method 2 — check_worstcase_dominance","text":"data.frame two columns: first column records values \\(\\tau\\) second column records whether method 1 worst-case-upper-dominates method 2 quantile \\(w\\[\\Gamma^{-1}, \\Gamma]\\)","code":""},{"path":"/reference/check_worstcase_dominance.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check if method 1 worst-case-upper-dominates method 2 — check_worstcase_dominance","text":"err one following forms. square asymmetric matrix number training domains \\(r = 1\\). case, err[, j] records transfer error using -th domain training j-th domain testing. data.frame \\((r+2)\\) columns. last column records transfer errors, second last column records indices test domains, first r columns record indices training domains. (recommended) data.frame two columns. second column records transfer errors first column records indices test domains. version, recommended include transfer errors n-choose-(r+1) combinations training test domains. Otherwise, ete_interval can still output interval, though theoretical guarantee unclear.","code":""},{"path":"/reference/check_worstcase_dominance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check if method 1 worst-case-upper-dominates method 2 — check_worstcase_dominance","text":"","code":"# Generate three error matrices such that # errmat1 and errmat2 are similar  # and errmat1 is smaller than errmat3 n <- 40 set.seed(1) errmat1 <- matrix(runif(n^2), nrow = n) errmat2 <- matrix(runif(n^2), nrow = n) errmat3 <- errmat1 + 0.1 diag(errmat1) <- diag(errmat2) <- diag(errmat3) <- NA  check_worstcase_dominance(errmat1, errmat2) #>     tau   res #> 1  0.50 FALSE #> 2  0.51 FALSE #> 3  0.52 FALSE #> 4  0.53 FALSE #> 5  0.54  TRUE #> 6  0.55  TRUE #> 7  0.56  TRUE #> 8  0.57 FALSE #> 9  0.58 FALSE #> 10 0.59  TRUE #> 11 0.60  TRUE #> 12 0.61  TRUE #> 13 0.62  TRUE #> 14 0.63  TRUE #> 15 0.64  TRUE #> 16 0.65  TRUE #> 17 0.66  TRUE #> 18 0.67 FALSE #> 19 0.68 FALSE #> 20 0.69 FALSE #> 21 0.70 FALSE #> 22 0.71 FALSE #> 23 0.72 FALSE #> 24 0.73 FALSE #> 25 0.74 FALSE #> 26 0.75 FALSE #> 27 0.76 FALSE #> 28 0.77  TRUE #> 29 0.78  TRUE #> 30 0.79  TRUE #> 31 0.80  TRUE #> 32 0.81  TRUE #> 33 0.82  TRUE #> 34 0.83  TRUE #> 35 0.84  TRUE #> 36 0.85 FALSE #> 37 0.86 FALSE #> 38 0.87 FALSE #> 39 0.88  TRUE #> 40 0.89  TRUE #> 41 0.90 FALSE #> 42 0.91 FALSE #> 43 0.92 FALSE #> 44 0.93 FALSE #> 45 0.94 FALSE #> 46 0.95 FALSE #> 47 0.96 FALSE #> 48 0.97 FALSE #> 49 0.98  TRUE #> 50 0.99  TRUE #> 51 1.00  TRUE check_worstcase_dominance(errmat1, errmat3) #>     tau  res #> 1  0.50 TRUE #> 2  0.51 TRUE #> 3  0.52 TRUE #> 4  0.53 TRUE #> 5  0.54 TRUE #> 6  0.55 TRUE #> 7  0.56 TRUE #> 8  0.57 TRUE #> 9  0.58 TRUE #> 10 0.59 TRUE #> 11 0.60 TRUE #> 12 0.61 TRUE #> 13 0.62 TRUE #> 14 0.63 TRUE #> 15 0.64 TRUE #> 16 0.65 TRUE #> 17 0.66 TRUE #> 18 0.67 TRUE #> 19 0.68 TRUE #> 20 0.69 TRUE #> 21 0.70 TRUE #> 22 0.71 TRUE #> 23 0.72 TRUE #> 24 0.73 TRUE #> 25 0.74 TRUE #> 26 0.75 TRUE #> 27 0.76 TRUE #> 28 0.77 TRUE #> 29 0.78 TRUE #> 30 0.79 TRUE #> 31 0.80 TRUE #> 32 0.81 TRUE #> 33 0.82 TRUE #> 34 0.83 TRUE #> 35 0.84 TRUE #> 36 0.85 TRUE #> 37 0.86 TRUE #> 38 0.87 TRUE #> 39 0.88 TRUE #> 40 0.89 TRUE #> 41 0.90 TRUE #> 42 0.91 TRUE #> 43 0.92 TRUE #> 44 0.93 TRUE #> 45 0.94 TRUE #> 46 0.95 TRUE #> 47 0.96 TRUE #> 48 0.97 TRUE #> 49 0.98 TRUE #> 50 0.99 TRUE #> 51 1.00 TRUE  # Transform error matrices into data.frames with r+2=3 columns idx <- expand.grid(train = 1:n, test = 1:n) errdf1 <- cbind(idx, data.frame(val = as.numeric(errmat1))) errdf1 <- errdf1[!is.na(errdf1$val), ] errdf2 <- cbind(idx, data.frame(val = as.numeric(errmat2))) errdf2 <- errdf2[!is.na(errdf2$val), ] errdf3 <- cbind(idx, data.frame(val = as.numeric(errmat3))) errdf3 <- errdf3[!is.na(errdf3$val), ]  check_worstcase_dominance(errdf1, errdf2) #>     tau   res #> 1  0.50 FALSE #> 2  0.51 FALSE #> 3  0.52 FALSE #> 4  0.53 FALSE #> 5  0.54  TRUE #> 6  0.55  TRUE #> 7  0.56  TRUE #> 8  0.57 FALSE #> 9  0.58 FALSE #> 10 0.59  TRUE #> 11 0.60  TRUE #> 12 0.61  TRUE #> 13 0.62  TRUE #> 14 0.63  TRUE #> 15 0.64  TRUE #> 16 0.65  TRUE #> 17 0.66  TRUE #> 18 0.67 FALSE #> 19 0.68 FALSE #> 20 0.69 FALSE #> 21 0.70 FALSE #> 22 0.71 FALSE #> 23 0.72 FALSE #> 24 0.73 FALSE #> 25 0.74 FALSE #> 26 0.75 FALSE #> 27 0.76 FALSE #> 28 0.77  TRUE #> 29 0.78  TRUE #> 30 0.79  TRUE #> 31 0.80  TRUE #> 32 0.81  TRUE #> 33 0.82  TRUE #> 34 0.83  TRUE #> 35 0.84  TRUE #> 36 0.85 FALSE #> 37 0.86 FALSE #> 38 0.87 FALSE #> 39 0.88  TRUE #> 40 0.89  TRUE #> 41 0.90 FALSE #> 42 0.91 FALSE #> 43 0.92 FALSE #> 44 0.93 FALSE #> 45 0.94 FALSE #> 46 0.95 FALSE #> 47 0.96 FALSE #> 48 0.97 FALSE #> 49 0.98  TRUE #> 50 0.99  TRUE #> 51 1.00  TRUE check_worstcase_dominance(errdf1, errdf3) #>     tau  res #> 1  0.50 TRUE #> 2  0.51 TRUE #> 3  0.52 TRUE #> 4  0.53 TRUE #> 5  0.54 TRUE #> 6  0.55 TRUE #> 7  0.56 TRUE #> 8  0.57 TRUE #> 9  0.58 TRUE #> 10 0.59 TRUE #> 11 0.60 TRUE #> 12 0.61 TRUE #> 13 0.62 TRUE #> 14 0.63 TRUE #> 15 0.64 TRUE #> 16 0.65 TRUE #> 17 0.66 TRUE #> 18 0.67 TRUE #> 19 0.68 TRUE #> 20 0.69 TRUE #> 21 0.70 TRUE #> 22 0.71 TRUE #> 23 0.72 TRUE #> 24 0.73 TRUE #> 25 0.74 TRUE #> 26 0.75 TRUE #> 27 0.76 TRUE #> 28 0.77 TRUE #> 29 0.78 TRUE #> 30 0.79 TRUE #> 31 0.80 TRUE #> 32 0.81 TRUE #> 33 0.82 TRUE #> 34 0.83 TRUE #> 35 0.84 TRUE #> 36 0.85 TRUE #> 37 0.86 TRUE #> 38 0.87 TRUE #> 39 0.88 TRUE #> 40 0.89 TRUE #> 41 0.90 TRUE #> 42 0.91 TRUE #> 43 0.92 TRUE #> 44 0.93 TRUE #> 45 0.94 TRUE #> 46 0.95 TRUE #> 47 0.96 TRUE #> 48 0.97 TRUE #> 49 0.98 TRUE #> 50 0.99 TRUE #> 51 1.00 TRUE  # Transform error matrices into data.frames with only two columns (not recommended) errdf1_2 <- errdf1[, 2:3] errdf2_2 <- errdf2[, 2:3] errdf3_2 <- errdf3[, 2:3]  check_worstcase_dominance(errdf1_2, errdf2_2) #>     tau   res #> 1  0.50 FALSE #> 2  0.51 FALSE #> 3  0.52 FALSE #> 4  0.53 FALSE #> 5  0.54  TRUE #> 6  0.55  TRUE #> 7  0.56  TRUE #> 8  0.57 FALSE #> 9  0.58 FALSE #> 10 0.59  TRUE #> 11 0.60  TRUE #> 12 0.61  TRUE #> 13 0.62  TRUE #> 14 0.63  TRUE #> 15 0.64  TRUE #> 16 0.65  TRUE #> 17 0.66  TRUE #> 18 0.67 FALSE #> 19 0.68 FALSE #> 20 0.69 FALSE #> 21 0.70 FALSE #> 22 0.71 FALSE #> 23 0.72 FALSE #> 24 0.73 FALSE #> 25 0.74 FALSE #> 26 0.75 FALSE #> 27 0.76 FALSE #> 28 0.77  TRUE #> 29 0.78  TRUE #> 30 0.79  TRUE #> 31 0.80  TRUE #> 32 0.81  TRUE #> 33 0.82  TRUE #> 34 0.83  TRUE #> 35 0.84  TRUE #> 36 0.85 FALSE #> 37 0.86 FALSE #> 38 0.87 FALSE #> 39 0.88  TRUE #> 40 0.89  TRUE #> 41 0.90 FALSE #> 42 0.91 FALSE #> 43 0.92 FALSE #> 44 0.93 FALSE #> 45 0.94 FALSE #> 46 0.95 FALSE #> 47 0.96 FALSE #> 48 0.97 FALSE #> 49 0.98  TRUE #> 50 0.99  TRUE #> 51 1.00  TRUE check_worstcase_dominance(errdf1_2, errdf3_2) #>     tau  res #> 1  0.50 TRUE #> 2  0.51 TRUE #> 3  0.52 TRUE #> 4  0.53 TRUE #> 5  0.54 TRUE #> 6  0.55 TRUE #> 7  0.56 TRUE #> 8  0.57 TRUE #> 9  0.58 TRUE #> 10 0.59 TRUE #> 11 0.60 TRUE #> 12 0.61 TRUE #> 13 0.62 TRUE #> 14 0.63 TRUE #> 15 0.64 TRUE #> 16 0.65 TRUE #> 17 0.66 TRUE #> 18 0.67 TRUE #> 19 0.68 TRUE #> 20 0.69 TRUE #> 21 0.70 TRUE #> 22 0.71 TRUE #> 23 0.72 TRUE #> 24 0.73 TRUE #> 25 0.74 TRUE #> 26 0.75 TRUE #> 27 0.76 TRUE #> 28 0.77 TRUE #> 29 0.78 TRUE #> 30 0.79 TRUE #> 31 0.80 TRUE #> 32 0.81 TRUE #> 33 0.82 TRUE #> 34 0.83 TRUE #> 35 0.84 TRUE #> 36 0.85 TRUE #> 37 0.86 TRUE #> 38 0.87 TRUE #> 39 0.88 TRUE #> 40 0.89 TRUE #> 41 0.90 TRUE #> 42 0.91 TRUE #> 43 0.92 TRUE #> 44 0.93 TRUE #> 45 0.94 TRUE #> 46 0.95 TRUE #> 47 0.96 TRUE #> 48 0.97 TRUE #> 49 0.98 TRUE #> 50 0.99 TRUE #> 51 1.00 TRUE  # Generate an error data.frame with r>1 n <- 20 set.seed(1) idx <- expand.grid(train1 = 1:n, train2 = 1:n, test = 1:n) idx <- idx[idx$train1 != idx$train2 & idx$train1 != idx$test & idx$train2 != idx$test, ] err1 <- cbind(idx, data.frame(val = runif(nrow(idx)))) err2 <- cbind(idx, data.frame(val = runif(nrow(idx)))) err3 <- cbind(idx, data.frame(val = err1$val + 0.1))  check_worstcase_dominance(err1, err2) #>     tau   res #> 1  0.50 FALSE #> 2  0.51 FALSE #> 3  0.52 FALSE #> 4  0.53 FALSE #> 5  0.54 FALSE #> 6  0.55 FALSE #> 7  0.56 FALSE #> 8  0.57 FALSE #> 9  0.58 FALSE #> 10 0.59 FALSE #> 11 0.60 FALSE #> 12 0.61 FALSE #> 13 0.62 FALSE #> 14 0.63 FALSE #> 15 0.64 FALSE #> 16 0.65 FALSE #> 17 0.66 FALSE #> 18 0.67 FALSE #> 19 0.68 FALSE #> 20 0.69 FALSE #> 21 0.70 FALSE #> 22 0.71 FALSE #> 23 0.72 FALSE #> 24 0.73 FALSE #> 25 0.74 FALSE #> 26 0.75 FALSE #> 27 0.76 FALSE #> 28 0.77 FALSE #> 29 0.78 FALSE #> 30 0.79 FALSE #> 31 0.80 FALSE #> 32 0.81 FALSE #> 33 0.82 FALSE #> 34 0.83 FALSE #> 35 0.84 FALSE #> 36 0.85 FALSE #> 37 0.86 FALSE #> 38 0.87 FALSE #> 39 0.88 FALSE #> 40 0.89 FALSE #> 41 0.90 FALSE #> 42 0.91 FALSE #> 43 0.92 FALSE #> 44 0.93 FALSE #> 45 0.94 FALSE #> 46 0.95 FALSE #> 47 0.96 FALSE #> 48 0.97 FALSE #> 49 0.98 FALSE #> 50 0.99 FALSE #> 51 1.00 FALSE check_worstcase_dominance(err1, err3) #>     tau  res #> 1  0.50 TRUE #> 2  0.51 TRUE #> 3  0.52 TRUE #> 4  0.53 TRUE #> 5  0.54 TRUE #> 6  0.55 TRUE #> 7  0.56 TRUE #> 8  0.57 TRUE #> 9  0.58 TRUE #> 10 0.59 TRUE #> 11 0.60 TRUE #> 12 0.61 TRUE #> 13 0.62 TRUE #> 14 0.63 TRUE #> 15 0.64 TRUE #> 16 0.65 TRUE #> 17 0.66 TRUE #> 18 0.67 TRUE #> 19 0.68 TRUE #> 20 0.69 TRUE #> 21 0.70 TRUE #> 22 0.71 TRUE #> 23 0.72 TRUE #> 24 0.73 TRUE #> 25 0.74 TRUE #> 26 0.75 TRUE #> 27 0.76 TRUE #> 28 0.77 TRUE #> 29 0.78 TRUE #> 30 0.79 TRUE #> 31 0.80 TRUE #> 32 0.81 TRUE #> 33 0.82 TRUE #> 34 0.83 TRUE #> 35 0.84 TRUE #> 36 0.85 TRUE #> 37 0.86 TRUE #> 38 0.87 TRUE #> 39 0.88 TRUE #> 40 0.89 TRUE #> 41 0.90 TRUE #> 42 0.91 TRUE #> 43 0.92 TRUE #> 44 0.93 TRUE #> 45 0.94 TRUE #> 46 0.95 TRUE #> 47 0.96 TRUE #> 48 0.97 TRUE #> 49 0.98 TRUE #> 50 0.99 TRUE #> 51 1.00 TRUE"},{"path":"/reference/forecast_interval.html","id":null,"dir":"Reference","previous_headings":"","what":"Forecast intervals for transfer errors — forecast_interval","title":"Forecast intervals for transfer errors — forecast_interval","text":"forecast_interval generates one- two-sided forecast intervals transfer errors (Section 3) given coverage level without finite-sample correction.","code":""},{"path":"/reference/forecast_interval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forecast intervals for transfer errors — forecast_interval","text":"","code":"forecast_interval(   err,   coverage,   side = c(\"two\", \"left\", \"right\"),   correction = FALSE )"},{"path":"/reference/forecast_interval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forecast intervals for transfer errors — forecast_interval","text":"err error object; see Details coverage target coverage level side \"two\" two-sided, \"left\" intervals form \\([, \\infty)\\), \"right\" intervals form \\((-\\infty, ]\\) correction TRUE correction performed guarantee coverage alpha finite samples; FALSE correction performed; see Details","code":""},{"path":"/reference/forecast_interval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forecast intervals for transfer errors — forecast_interval","text":"interval vector length 2","code":""},{"path":"/reference/forecast_interval.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Forecast intervals for transfer errors — forecast_interval","text":"err one following forms. square asymmetric matrix number training domains \\(r = 1\\). case, err[, j] records transfer error using -th domain training j-th domain testing. data.frame \\((r+2)\\) columns. last column records transfer errors, second last column records indices test domains, first r columns record indices training domains. (recommended) data.frame two columns. second column records transfer errors first column records indices test domains. version, recommended include transfer errors n-choose-(r+1) combinations training test domains. Otherwise, forecast_interval can still output interval, though theoretical guarantee unclear. correction = FALSE, output \\([\\underline{e}_{(1+\\tau)/2}^{\\mathbf{M}}, \\overline{e}_{(1+\\tau)/2}^{\\mathbf{M}}]\\) side = \"two\"; \\([\\underline{e}_{\\tau}^{\\mathbf{M}}, \\infty)\\) side = \"left\"; \\((-\\infty, \\overline{e}_{\\tau}^{\\mathbf{M}}]\\) side = \"right\", \\(\\tau\\) given coverage. theoretical lower bound coverage smaller \\(\\tau\\) (Proposition 1) gap \\(O(r/n)\\). correction = TRUE, first multiplies coverage \\((n + 1) / (n - r)\\) outputs interval. Proposition 1 implies coverage lower bounded \\(\\tau\\) finite samples.","code":""},{"path":"/reference/forecast_interval.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Forecast intervals for transfer errors — forecast_interval","text":"","code":"# Generate an error matrix n <- 100 set.seed(1) errmat <- matrix(runif(n^2), nrow = n) diag(errmat) <- NA  # Two-sided forecast intervals without and with finite-sample correction forecast_interval(errmat, 0.9, \"two\", correction = FALSE) #> [1] 0.04861056 0.95264364 forecast_interval(errmat, 0.9, \"two\", correction = TRUE) #> [1] 0.03910006 0.96040231  # One-sided forecast intervals without and with finite-sample correction forecast_interval(errmat, 0.9, \"left\", correction = FALSE) #> [1] 0.09737435        Inf forecast_interval(errmat, 0.9, \"left\", correction = TRUE) #> [1] 0.07821896        Inf forecast_interval(errmat, 0.9, \"right\", correction = FALSE) #> [1]      -Inf 0.9039679 forecast_interval(errmat, 0.9, \"right\", correction = TRUE) #> [1]      -Inf 0.9219315  # Generate an error data.frame with r+2=3 columns idx <- expand.grid(train = 1:n, test = 1:n) errdf <- cbind(idx, data.frame(val = as.numeric(errmat))) errdf <- errdf[!is.na(errdf$val), ] forecast_interval(errdf, 0.9, \"two\", correction = FALSE) #> [1] 0.04861056 0.95264364 forecast_interval(errmat, 0.9, \"two\", correction = FALSE) #> [1] 0.04861056 0.95264364  # Generate an error data.frame with only two columns (not recommended) errdf2 <- errdf[, 2:3] forecast_interval(errdf2, 0.9, \"two\", correction = FALSE) #> [1] 0.04861056 0.95264364  # Generate an error data.frame with r>1 n <- 40 set.seed(1) idx <- expand.grid(train1 = 1:n, train2 = 1:n, test = 1:n) idx <- idx[idx$train1 != idx$train2 & idx$train1 != idx$test & idx$train2 != idx$test, ] err <- cbind(idx, data.frame(val = runif(nrow(idx))))  # Two-sided forecast intervals without and with finite-sample correction forecast_interval(err, 0.9, \"two\", correction = FALSE) #> [1] 0.04999229 0.95099817 forecast_interval(err, 0.9, \"two\", correction = TRUE) #> [1] 0.01426661 0.98641024  # One-sided forecast intervals without and with finite-sample correction forecast_interval(err, 0.9, \"left\", correction = FALSE) #> [1] 0.09928197        Inf forecast_interval(err, 0.9, \"left\", correction = TRUE) #> [1] 0.02866646        Inf forecast_interval(err, 0.9, \"right\", correction = FALSE) #> [1]      -Inf 0.9009274 forecast_interval(err, 0.9, \"right\", correction = TRUE) #> [1]     -Inf 0.972384"},{"path":"/reference/inv_ustat_HBM_upper.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse of \\(B_{n, k}(x; \\mu)\\) at \\(alpha\\) given \\(x\\) or\n\\(\\mu\\) val measures ","title":"Inverse of \\(B_{n, k}(x; \\mu)\\) at \\(alpha\\) given \\(x\\) or\n\\(\\mu\\) val measures ","text":"Inverse \\(B_{n, k}(x; \\mu)\\) \\(alpha\\) given \\(x\\) \\(\\mu\\) val measures \"x\" type = \"mu\" \"mu\" type = \"x\". Setting type = \"x\" yields \\(\\inf{y: B_{n, k}(y; \\mu) \\ge \\alpha}\\) setting type = \"mu\" yields \\(\\inf{\\nu: B_{n, k}(x; \\nu) \\ge \\alpha}\\)","code":""},{"path":"/reference/inv_ustat_HBM_upper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inverse of \\(B_{n, k}(x; \\mu)\\) at \\(alpha\\) given \\(x\\) or\n\\(\\mu\\) val measures ","text":"","code":"inv_ustat_HBM_upper(val, n, k, alpha, type = c(\"x\", \"mu\"))"},{"path":"/reference/inv_ustat_HBM_upper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse of \\(B_{n, k}(x; \\mu)\\) at \\(alpha\\) given \\(x\\) or\n\\(\\mu\\) val measures ","text":"val value either \"x\" \"mu\" n sample size k order U statistic alpha confidence level type see Details","code":""},{"path":"/reference/inv_ustat_HBM_upper.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inverse of \\(B_{n, k}(x; \\mu)\\) at \\(alpha\\) given \\(x\\) or\n\\(\\mu\\) val measures ","text":"inverse \\(B_{n, k}(x; \\mu)\\)","code":""}]
